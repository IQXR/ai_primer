{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd3a42efa31ff3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 04- Regularization\n",
    "\n",
    "Regularization trades a marginal decrease in training accuracy for an increase in generalizability. Regularization encompasses a range of techniques to correct for overfitting in machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83898166-5ad9-410c-b211-b43371db5481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e246ed2-a6e9-4440-aa97-8a4104e1d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c9bd8-d5c7-407b-b766-be0f7937f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model tools\n",
    "from scripts.model_tools import train_validate, test_validate, set_fashion_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd0b0c-21df-4c17-bebf-c6d4cdbef44a",
   "metadata": {},
   "source": [
    "## Recreate last model\n",
    "\n",
    "Let's recreate the Deep Neural Network from last notebook for comparison. But we'll decrease the learning rate to it's original values for smoother results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f1f01-3bba-44ff-a8ef-6f07c856827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "HIDDEN_LAYER_PARAMETERS = [64, 48, 24]\n",
    "LEARNING_RATE = 0.003\n",
    "EPOCHS = 15\n",
    "OUTPUTS = 10\n",
    "RATIO_VALIDATION = 0.2\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35ee17-73cf-4faf-a54d-1c9c81bc70e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_ds, test_ds, train_dl, val_dl, test_dl, classes = set_fashion_dataset(transform, RATIO_VALIDATION, BATCH_SIZE)\n",
    "image, label = next(iter(train_dl))\n",
    "input_features = image[0].shape[0] * image[0].shape[1] * image[0].shape[2] # Total input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c322391a-33f6-4806-8dea-997dd6b3ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(OrderedDict([('fc1', nn.Linear(input_features, HIDDEN_LAYER_PARAMETERS[0])),\n",
    "                                   ('relu1', nn.ReLU()),\n",
    "                                   ('fc2', nn.Linear(HIDDEN_LAYER_PARAMETERS[0], HIDDEN_LAYER_PARAMETERS[1])),\n",
    "                                   ('relu2', nn.ReLU()),\n",
    "                                   ('fc3', nn.Linear(HIDDEN_LAYER_PARAMETERS[1], HIDDEN_LAYER_PARAMETERS[2])),\n",
    "                                   ('relu3', nn.ReLU()),\n",
    "                                   ('output', nn.Linear(HIDDEN_LAYER_PARAMETERS[2], OUTPUTS)),\n",
    "                                   ('logsoftmax', nn.LogSoftmax(dim=1))]))\n",
    "model = model.to(device)\n",
    "loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef2305-162b-4977-a5f1-dbd5b295f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validate(model, loss_fn, optimizer, train_dl, val_dl, device, n_epochs = EPOCHS, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc388bc2-02fc-41ec-937e-a7b822ae1c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_validate(model, test_dl, device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a16239a-058f-4fdd-b437-4555ebe0b7ff",
   "metadata": {},
   "source": [
    "## Normalize Input Dataset\n",
    "\n",
    "Input features can vary in different scales. By setting inputs to zero mean and unit variance, that guarantees that all your features are in a similar scale. This usually helps your learning algorithm run faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05592de-ce1c-42b1-8a20-14f734be616b",
   "metadata": {},
   "source": [
    "Remember gradient descent?  Well, imagine it like a ball rolling down to the lowest point in the valleys shown below. With unnormalized inputs, there will be a lot of time spent bouncing back and forth in the uneven terrain. With normalized inputs, the way down is a lot smoother."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd0bb34-d120-46c9-be97-46d1aba880b1",
   "metadata": {},
   "source": [
    "![](../media/regularization/Normalization.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721cbe20-f936-4958-ba44-e15ecc82a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add input normalization\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)) # Notice normalization. This only happens during training\n",
    "    ])\n",
    "train_ds, test_ds, train_dl, val_dl, test_dl, classes = set_fashion_dataset(transform, RATIO_VALIDATION, BATCH_SIZE)\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54b7b7-32c9-44b7-80e3-1d8b5584b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b79d411-9a34-480d-aa9a-b758b62c2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validate(model, loss_fn, optimizer, train_dl, val_dl, device, n_epochs = EPOCHS, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e89e44-3445-48e5-a5ba-aba344e5ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_validate(model, test_dl, device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f82a80-ad8b-4aee-ac83-306fb6de44eb",
   "metadata": {},
   "source": [
    "Since the images are in Black/White, both axes are on the 0-255 range, and generally there is a similar amount of white pixels on black background, normalization doesn't achieve much. It's an important tool for more varied datasets, like color photographs, or data with different scales (e.g, income vs age)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7660e9af-3afd-457b-85a7-db57f29851d5",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "By randomly dropping out neurons during training, we force the model to not rely on any single feature. Dropout helps break co-adaptations among units, and each unit can act more independently when dropout regularization is used.\n",
    "\n",
    "This makes it more robust against data it hasn't seen before. It requires more epochs to converge due to its stochastic nature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfcc73d-39ba-485a-a722-0229e2e34677",
   "metadata": {},
   "source": [
    "![](../media/regularization/Dropout.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd678f-740b-43c6-a130-90fce36c0ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout layers\n",
    "model = nn.Sequential(OrderedDict([('fc1', nn.Linear(input_features, HIDDEN_LAYER_PARAMETERS[0])),\n",
    "                                   ('relu1', nn.ReLU()),\n",
    "                                   ('drop1', nn.Dropout(0.20)), # Dropout layer\n",
    "                                   ('fc2', nn.Linear(HIDDEN_LAYER_PARAMETERS[0], HIDDEN_LAYER_PARAMETERS[1])),\n",
    "                                   ('relu2', nn.ReLU()),\n",
    "                                   ('output', nn.Linear(HIDDEN_LAYER_PARAMETERS[1], OUTPUTS)),\n",
    "                                   ('logsoftmax', nn.LogSoftmax(dim=1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ce6990-ded0-4997-b824-b95aaba7b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase number of epochs\n",
    "dropout_epochs = int(EPOCHS * (1.25))\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0998d77d-a0a7-416f-8ba3-b2621bcaeed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validate(model, loss_fn, optimizer, train_dl, val_dl, device, n_epochs = dropout_epochs, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16deb836-07b8-4472-9182-7bac6e988516",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_validate(model, test_dl, device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34524c-c0c5-4a07-8a76-41d2286490c8",
   "metadata": {},
   "source": [
    "Notice that the validation loss, which comes from unseen data during training, has been reduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf5d153-febe-43bc-b987-f45aa5e9d4a2",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "Data augmentation techniques include random rotations, zooms, crops, flips, and distortions to generate more data from the available image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b3ad8-c816-438f-b249-337fdf26385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6ba6e-1aa6-4844-acf4-ad2efecad167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single sample image\n",
    "image, label = next(iter(train_dl))\n",
    "index = 0 # Only first image\n",
    "print(classes[label[index].item()])\n",
    "plt.imshow(image[index].numpy().squeeze(), cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ef4ad-c781-4ca7-86df-e1c1131f3995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a subset of our dataset\n",
    "indices = torch.arange(1)\n",
    "train_ds_one = torch.utils.data.Subset(train_ds, indices)\n",
    "train_dl_one = DataLoader(train_ds_one, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7b9fd-a978-4d98-8623-b7da98c94552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add random rotation to our transformations\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "transform_rotate = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "        transforms.RandomRotation(25), # Random rotate +/- degrees\n",
    "    ])\n",
    "train_ds_one.dataset.transform = transform_rotate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad4995c-d1ad-4989-ac3f-b6adbec14dac",
   "metadata": {},
   "source": [
    "Notice that data augmentation does not actually expand your dataset. Data augmentation transformations are applied on each item in the dataset one by one, and not adding to the size of the dataset. Every epoch you get a different version of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda02f85-4ca0-4643-a3e2-9f741e3fb527",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_passes = 4\n",
    "\n",
    "f, ax_arr = plt.subplots(1, number_of_passes, squeeze=False)\n",
    "index = 0 # Only one image\n",
    "print(classes[label[index].item()])\n",
    "for j, row in enumerate(ax_arr):\n",
    "    for i, ax in enumerate(row):\n",
    "        image, label = next(iter(train_dl_one))\n",
    "        ax.imshow(image[index].numpy().squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c588a2-fb6d-42fc-94c8-6179a5620b96",
   "metadata": {},
   "source": [
    "Why the grey area? It's being filled with the default color for `RandomRotation`, which is black. *However*, we had already normalized our data! The value for black, 0, is the mean in the value spectrum, which turns out to be grey. If you want to avoid this, the transformation above should do `RandomRotation`, then `Normalize` afterwards. It is important to check your assumptions when dealing with datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0731d286-4b36-4e77-b944-8b5da4d33340",
   "metadata": {},
   "source": [
    "### Apply to whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4f0e0-2c03-4332-821a-f7aa6f77403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.transform = transform_rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a107510-a427-4e7c-b150-25d8d3087815",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "train_validate(model, loss_fn, optimizer, train_dl, val_dl, device, n_epochs = EPOCHS, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc9c32d-0662-4ba2-a0bd-5c9ce8c1425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_validate(model, test_dl, device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b503e5-1669-4b71-9f27-80bb5c0a60fc",
   "metadata": {},
   "source": [
    "In this case, our train data orientation was very well matched with the test data orientation, so data augmentation of rotation type worked against us. For real world photographs, it would probably make our dataset better suited and compensate for small datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d841926-f9a6-4d7f-8e71-561cb4890d03",
   "metadata": {},
   "source": [
    "**Next Notebook: [05-Convolutional Neural Networks](05-CNN.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d134fd9-da44-4b56-9fc9-91c5f19bbee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
