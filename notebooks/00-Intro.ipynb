{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd3a42efa31ff3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Artificial Intelligence Primer\n",
    "\n",
    "Welcome! This project offers a quick view and practical examples for AI, avoiding the complex installation setup.\n",
    "\n",
    "We will start will the concepts of Artificial Intelligence, Machine Learning, Deep Learning, and AI frameworks. Then we will explore each architecture in increasing level of complexity and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f4470-8911-4a9a-8f0a-d1e700eb530f",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "\n",
    "This is a Jupyter notebook. Notice that we can have both prose, like this explanation, and code, like the cell below. To execute the cell below, select it and press the ▶️ (*Run this cell and Advance*) icon in the toolbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88800966-4135-459e-b57c-ba36013fa0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print('Hello World!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f3f63-3ec6-4ee3-98f0-34f8b0537f7f",
   "metadata": {},
   "source": [
    "The shortcut for execution is `Shift` + `Enter`.\n",
    "\n",
    "Optionally, you can press the ⏩ (*Restart the kernel and run all cells*) icon to execute the whole notebook at once. Since this is a learning and not a production notebook, we recommend you step one cell at a time instead.\n",
    "\n",
    "Notice that you can execute cells in any order, or multiple times. The history of cell execution is labeled to the left of each cell, like \\[1\\] indicating this is the first cell that was executed. Most notebooks expect a linear progression, but you can re-run any cell at any time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039808fa-191d-4b99-bc1a-ba5a801f6e6c",
   "metadata": {},
   "source": [
    "## Concepts\n",
    "\n",
    "You probably have heard AI-related concepts before, but it's good to review their hierarchy.\n",
    "\n",
    "![](../media/intro/A-comparative-view-of-AI-machine-learning-deep-learning-and-generative-AI-source.png \"Miltiadis D. Lytras\")\n",
    "\n",
    "To allow work in AI, we have different tools:\n",
    "\n",
    "- **Python**: Python is the primary language we'll be using for AI.\n",
    "- **PyTorch & torchvision**: PyTorch is an open-source machine learning library, and torchvision offers datasets and models for computer vision.\n",
    "- **Jupyter Notebook**: The interactive environment where this tutorial is presented.\n",
    "- **NumPy**: A library for numerical operations in Python.\n",
    "- **scikit-learn**: Machine learning library in Python. We'll use it for performance metrics.\n",
    "- **Seaborn & Matplotlib**: Visualization libraries in Python.\n",
    "- **CUDA** (Optional): If you have a compatible NVIDIA GPU, you can install CUDA for GPU acceleration with PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11673206-2fdf-4cb2-916b-8f84775840ed",
   "metadata": {},
   "source": [
    "# Artitifical Intelligence Summary\n",
    "\n",
    "Below is a summary of the main concepts of Articial Intelligence. It's very condensed but it'll give you the reasoning behind each concept. For more in-depth information, you can search online, there's plenty of material there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe00dd89-82d5-466b-804c-d71e6f63e174",
   "metadata": {},
   "source": [
    "## Neural Networks and Deep Learning\n",
    "\n",
    "\n",
    "Traditional learning algorithms do not scale with the amount of data. So Deep Learning takes advantage of large amounts of labeled data to increase performance of analyses, predictions, and classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5786a4a0-65bb-4b43-80c1-8bf7b828c6f0",
   "metadata": {},
   "source": [
    "### Neural Network basics\n",
    "\n",
    "You probably recall from middle school that a linear function has the form `y = mx + b`. The basic neuron in a Neural Network also consists of a weight `w` and a bias `b`. This allows a neuron to change parameters to best fit a set of data.\n",
    "\n",
    "![](../media/intro/weights_and_biases.png \"@theDrewDag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17de76a8-9263-4448-b605-497adf7f5390",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "We don't know what the best equation to describe a set of data is, so we use linear regression to best fit the parameters to fit our data. In the graphs above, we would use (x,y) pairs as our data. For something like a cat classifier, we would use the value of each RGB pixel as our `x`, and our `y` would be whether the picture is of a cat or not. Because the answer is either True of False, this is a Binary CLassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6634b3db-45f6-4993-91e5-7169170f1e9a",
   "metadata": {},
   "source": [
    "#### Loss function\n",
    "\n",
    "How do we know is our system is doing a good job? We use the loss function. It measures how far away our prediction is from the expected result (label). This information is used to update our parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29beb5-4327-4bc4-bd82-e4de1328ae2b",
   "metadata": {},
   "source": [
    "#### Gradient Descent\n",
    "\n",
    "How do we update the numbers in our weight and biases parameters? We use derivatives on the cost function and a lot of math. We want to cost function to be minimized, so we use gradient descent to find the lowest cost point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd7904-6867-4587-a7ec-2a875bf1d28b",
   "metadata": {},
   "source": [
    "#### Activation function\n",
    "\n",
    "As it turns out, no matter how many neurons we use, if they are all linear functions, the end result if a linear function as well! This severely hinders our options. An activation function is non-linear, essentially allows us to say \"behave like this linear function, but only after a threshold.\" It's like adding a digital switch to an analog circuit, and it makes possible Neural Networks. A common activation function is the REctified Linuear Unit, ReLU.\n",
    "\n",
    "<img src=\"../media/intro/ReLU.png\" alt=\"ReLU\" style=\"width: 300px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841b4918-197e-4bf4-9393-68bdb35e2840",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "\n",
    "With each neuron having parameters (weight, bias) and an activation function (e.g, RELU), we can make a Neural Network, NN. A shallow NN may one internal layer, and it's fully connected.\n",
    "\n",
    "Displayed is also a deep NN has multiple hidden layers.\n",
    "\n",
    "![](../media/intro/Neural_networks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72292929-becf-4f13-8181-84f2e0893f24",
   "metadata": {},
   "source": [
    "#### Layers\n",
    "\n",
    "- The input layer is generally a flattened version of your data. For example, an linear array of each R, G, and B, value for each pixel in an image.\n",
    "- The hidden layers are your Neural Network Layers\n",
    "- The output layer corresponds to how many outputs you need. One for binary classification, multiple for categorization, etc.\n",
    "\n",
    "- Do you see the ReLU activation function above? It's unbounded and generally doesn't work for outputs, since they generally need boundaries. Foe example, probabilities are between 0 and 1. We generally use the sigmoid function for the output layer instead.\n",
    "- \n",
    "<img src=\"../media/intro/Sigmoid.png\" alt=\"Sigmoid\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecb3719-07ef-47ad-a16b-0051a8d6e0ec",
   "metadata": {},
   "source": [
    "### Forward and Backward Propagation\n",
    "\n",
    "We train NN from scratch. We put random weights and zero biases to start, and pass our training data through the NN to get predicted outputs. They will probably suck. But from the training data we know what they *should* be, so we calculate the loss function on that. And then we use these values to backpropagate changes into the NN, updating parameter values for weights and biases. And guess what? Our predictions would be better this time.\n",
    "\n",
    "So we do the forward pass, loss calculation, backward pass, and parameter update multiple times until we get close to expected results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970fb90e-2e08-4ed4-9cec-3bdddac51308",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "To tune our NN, we need to chose hyperparamaters. These are manually set variables that control the training process of a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f98a3-2d1f-446d-ba8a-0c215737d403",
   "metadata": {},
   "source": [
    "### Train / Dev / Test\n",
    "\n",
    "You have a labeled dataset, but your model should work on new data as well. So, split your dataset into training set, development set, and test set.\n",
    "\n",
    "- Train: data use to train the model.\n",
    "- Dev: data to use for hyperparameter tuning. Matches production data (e.g: traffic pictures from a specific webcam)\n",
    "- Test: This set is never seen during training, and is only used to determine accuracy. Matches production data.\n",
    "\n",
    "A hyperparameter would be what's the split between sets. Recommended for small datasets: ~60%, 20%, 20%. For large datasets (> 1 million): 98%, 1%, 1% "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1bb342-2d38-45db-bf4a-028d2bcaf826",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [pytorch-fashionMNIST-tutorial](https://github.com/junaidaliop/pytorch-fashionMNIST-tutorial/blob/main/pytorch_fashion_mnist_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6adfe0a-16b9-44c9-83b8-d229df3e0239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
